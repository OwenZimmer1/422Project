{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a3f966",
   "metadata": {},
   "source": [
    "## Things to add\n",
    " - multi shot prompt \n",
    " - chain of thought prompt \n",
    " - saving responses \n",
    " - chat memory (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd6ca5",
   "metadata": {},
   "source": [
    "# Model Testing \n",
    "\n",
    "**Here are my PC specs :)** \n",
    " - CPU: AMD 5900x (12 core, 24 thread)\n",
    " - GPU: RTX 3080ti (12gb VRAM)\n",
    " - MEMORY: 32gb 3600mhz\n",
    " - STORAGE: 2 x 2TB NVME\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29da2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the stuff we need\n",
    "import langchain\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aea266",
   "metadata": {},
   "source": [
    "## model selections \n",
    " - Qwen 2.5 coder (0.5b) \n",
    " - Qwen 2.5 coder (32b) \n",
    " - Wizardcoder (33b)\n",
    " - Starcoder (15b)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "374e640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick what model to use \n",
    "model1 = 'qwen2.5-coder:0.5b'\n",
    "model2 = 'qwen2.5-coder:32b'\n",
    "model3 = 'wizardcoder:33b'\n",
    "model4 = 'starcoder2:15b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1caede",
   "metadata": {},
   "source": [
    "## Prompt templates\n",
    " - one shot \n",
    " - multi shot\n",
    " - chain of thought \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0fc8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
      "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.33-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 2.0 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.0/1.0 MB 2.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 939.4 kB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 939.4 kB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.2/1.0 MB 958.4 kB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.3/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.4/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.1 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 225.3/434.1 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.1/434.1 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.33-py3-none-any.whl (358 kB)\n",
      "   ---------------------------------------- 0.0/358.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 358.8/358.8 kB 10.9 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/2.0 MB 9.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/2.0 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/2.0 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.9/2.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 162.0/162.0 kB 10.1 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.7/2.1 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.1 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 11.2 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.4/102.4 kB ? eta 0:00:00\n",
      "Downloading greenlet-3.2.0-cp311-cp311-win_amd64.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 295.4/295.4 kB 9.2 MB/s eta 0:00:00\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/78.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.7/78.7 kB 4.6 MB/s eta 0:00:00\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.16-cp311-cp311-win_amd64.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.8/133.8 kB 7.7 MB/s eta 0:00:00\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.5/54.5 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "   ---------------------------------------- 0.0/495.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 495.4/495.4 kB 10.5 MB/s eta 0:00:00\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tenacity, sniffio, PyYAML, pydantic-core, packaging, orjson, jsonpointer, idna, h11, greenlet, charset-normalizer, certifi, annotated-types, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, requests-toolbelt, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.1.31 charset-normalizer-3.4.1 greenlet-3.2.0 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.23 langchain-core-0.3.55 langchain-text-splitters-0.3.8 langsmith-0.3.33 orjson-3.10.16 packaging-24.2 pydantic-2.11.3 pydantic-core-2.33.1 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.0 urllib3-2.4.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\labib\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967fb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the prompt block\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneShot = PromptTemplate(\n",
    "    input_variables=[\"method_code\"],\n",
    "    template='''\n",
    "Write a clear and professional method header in Javadoc style. I will provide some examples.\n",
    "\n",
    "method_code: \n",
    "public int factorial(int n) {{\n",
    "    if (n < 0) {{\n",
    "        throw new IllegalArgumentException(\"Input must be non-negative.\");\n",
    "    }}\n",
    "    int result = 1;\n",
    "    for (int i = 2; i <= n; i++) {{\n",
    "        result *= i;\n",
    "    }}\n",
    "    return result;\n",
    "}}\n",
    "\n",
    "good output:\n",
    "/**\n",
    " * Calculates the factorial of a given non-negative integer.\n",
    " *\n",
    " * @param n the number to compute the factorial of\n",
    " * @return the factorial of n\n",
    " * @throws IllegalArgumentException if n is negative\n",
    " */\n",
    "\n",
    "now given {method_code}:\n",
    "\n",
    "write a Javadoc header for the method above.\n",
    "\n",
    "'''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca62019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from ollama import chat\n",
    "\n",
    "# Multishot examples from your dataset\n",
    "examples = \"\"\"\n",
    "public Point getLoc(){return location;}\n",
    "\n",
    "/***\n",
    "* Gets the location.\n",
    "*\n",
    "* @return the current location\n",
    "*/\n",
    "\n",
    "---\n",
    "\n",
    "public void draw(Graphics g){\n",
    "    g.setColor(color);\n",
    "    g.fillOval(location.intX() - radius, location.intY() - radius, radius * 2, radius * 2);\n",
    "    if (!active){\n",
    "        Vector standard_vec = move.normalize().scale(radius * 2);\n",
    "        g.setColor(Color.RED);\n",
    "        g.drawLine(location.intX(), location.intY(), standard_vec.move(location).intX(), standard_vec.move(location).intY());\n",
    "    }\n",
    "}\n",
    "\n",
    "/***\n",
    "* Draws the ball, and if non-active also draws its vector.\n",
    "*\n",
    "* @param g the Graphics context on which to draw\n",
    "*/\n",
    "\n",
    "---\n",
    "\n",
    "public boolean isDone(){\n",
    "    return finishedInstructions == totalInstructions;\n",
    "}\n",
    "\n",
    "/***\n",
    "* Checks if the process is completed.\n",
    "* \n",
    "* @return true, if the process has completed all instructions\n",
    "*/\n",
    "\"\"\"\n",
    "\n",
    "# Method to document\n",
    "new_method = \"\"\"\n",
    "private int add(int a, int b) {\n",
    "    return a + b;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Build the prompt using LangChain\n",
    "multiShot = PromptTemplate(\n",
    "    input_variables=[\"examples\", \"new_code\"],\n",
    "    template=\"\"\"\n",
    "Here are some examples of Java methods and their Javadoc comments:\n",
    "\n",
    "{examples}\n",
    "\n",
    "Now write a professional Javadoc comment for this Java method:\n",
    "\n",
    "{new_code}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_text = multiShot.format(examples=examples, new_code=new_method)\n",
    "\n",
    "# Run the model\n",
    "response = chat(model=\"qwen2.5-coder:0.5b\", messages=[{'role': 'user', 'content': prompt_text}])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ba9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainOfThought = PromptTemplate(\n",
    "    template='''\n",
    "Write to me a professional javadoc for this Java funcion. Here are the steps you should take:\n",
    "Is this method for a data structure? If so, what data structure?\n",
    "What are the parameters?\n",
    "What does the method do? Look at the name of the method\n",
    "How does the method do what it does? Are there edge cases?\n",
    "What exceptions does the method throw?\n",
    "What is the state of the object before the method is called?\n",
    "What is the state of the object after the method is called?\n",
    "What does the method return?\n",
    "Is this method overriding another method?\n",
    "Once you have finished the analysis, generate a professional javadoc with a clear description of what the method does, parameters taken in, return values, pre and post conditions, exceptions, and any other notes that should be in the javadoc. \n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec09162",
   "metadata": {},
   "outputs": [],
   "source": [
    "AdvancedChainOfThought = PromptTemplate(\n",
    "    template='''\n",
    "Write to me a professional javadoc for this Java funcion. Here are the steps you should take:\n",
    "Is this method for a data structure? If so, what data structure?\n",
    "What are the parameters?\n",
    "What does the method do? Look at the name of the method\n",
    "How does the method do what it does?\n",
    "What are the variable names used?\n",
    "How are the variables used?\n",
    "What exceptions does the method throw?\n",
    "What inputs will cause an exception to be thrown?\n",
    "Trace the execution with some test runs\n",
    "If the method is complex, break it into smaller chunks and analyze each chuck to see what the method does\n",
    "Once you have finished the analysis, generate a professional javadoc with a clear description of what the method does, parameters taken in, return values, pre and post conditions, exceptions, and any other notes that should be in the javadoc. \n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f42a9",
   "metadata": {},
   "source": [
    "## Sample code \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49fab33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeFromBST = oneShot.format(method_code=\n",
    "    \"\"\"private Node doRemove(Node r, String s, Node before, boolean removeOnce, Integer val) {\n",
    "\t\tif(r == null) {\n",
    "\t\t\tlastRemoved = null;\n",
    "\t\t\treturn null;\n",
    "\t\t}\n",
    "\t\tint c = s.compareTo(r.string);\n",
    "\t\tif(c < 0) r.left = doRemove(r.left, s, before, removeOnce, val);\n",
    "\t\telse if(c > 0) r.right = doRemove(r.right, s, r, removeOnce, val);\n",
    "\t\telse {\n",
    "\t\t\tif(val != null && val != r.count) return r;\n",
    "\t\t\tlastRemoved = r.count;\n",
    "\t\t\tif(removeOnce && r.count > 1) {\n",
    "\t\t\t\tr.count--;\n",
    "\t\t\t\treturn r;\n",
    "\t\t\t}\n",
    "\t\t\tif(before.next != r) {\n",
    "\t\t\t\tbefore = r.left;\n",
    "\t\t\t\twhile(before.right != null) before = before.right;\n",
    "\t\t\t}\n",
    "\t\t\tversion++;\n",
    "\t\t\tnumEntries--;\n",
    "\t\t\tif(r.left == null) {\n",
    "\t\t\t\tbefore.next = r.next;\n",
    "\t\t\t\treturn r.right;\n",
    "\t\t\t}\n",
    "\t\t\tif(r.right == null) {\n",
    "\t\t\t\tbefore.next = r.next;\n",
    "\t\t\t\treturn r.left;\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\t\t\tNode successor = r.right;\n",
    "\t\t\tNode prev = r;\n",
    "\t\t\twhile(successor.left != null) {\n",
    "\t\t\t\tprev = successor;\n",
    "\t\t\t\tsuccessor = successor.left;\n",
    "\t\t\t}\n",
    "\t\t\tr.string = successor.string;\n",
    "\t\t\tr.count = successor.count;\n",
    "\t\t\t\n",
    "\t\t\tif(prev.left == successor) prev.left = successor.right;\n",
    "\t\t\telse prev.right = successor.right;\n",
    "\t\t\t\n",
    "\t\t\tr.next = successor.next;\n",
    "\n",
    "\n",
    "\t\t}\n",
    "\t\treturn r;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1344b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some content \n",
    "shortMethod = oneShot.format(\n",
    "    method_code = \"\"\"\n",
    "    private void connect(HexPiece p) {\n",
    "HexCoordinate h = p.getLocation();\n",
    "for (HexDirection d : HexDirection.values()) {\n",
    "HexCoordinate h2 = d.move(h);\n",
    "HexPiece p2 = findPiece(h2);\n",
    "if (p2 != null) {\n",
    "p.neighbors[d.ordinal()] = p2;\n",
    "p2.neighbors[d.reverse().ordinal()] = p;\n",
    "}\n",
    "}\n",
    "}\n",
    "                         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dcd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "longMethodWithHelper = oneShot.format(method_code=\"\"\"\\\n",
    "private void rehash() {{\n",
    "\n",
    "    int newCapacity = Primes.nextPrime(table.length * 2);\n",
    "    HexPiece[] oldTable = table;\n",
    "    table = new HexPiece[newCapacity];\n",
    "    size = 0;\n",
    "\n",
    "    for (HexPiece head : oldTable) {{\n",
    "        if (head == null) continue;\n",
    "        HexPiece current = head;\n",
    "        do {{\n",
    "            HexPiece next = current.nextInChain;\n",
    "            int newIndex = locate(current.location);\n",
    "\n",
    "            if (table[newIndex] == null) {{\n",
    "                current.nextInChain = current;\n",
    "                table[newIndex] = current;\n",
    "            }} else {{\n",
    "                current.nextInChain = table[newIndex].nextInChain;\n",
    "                table[newIndex].nextInChain = current;\n",
    "            }}\n",
    "            size++;\n",
    "            current = next;\n",
    "        }} while (current != head);\n",
    "    }}\n",
    "}}\n",
    "\n",
    "public boolean add(HexPiece p) {{\n",
    "    assert wellFormed() : \"Invariant broken before add\";\n",
    "\n",
    "    if (p == null || p.location == null || p.terrain == null)\n",
    "        throw new NullPointerException(\"Piece, location, and terrain must not be null\");\n",
    "\n",
    "    int index = locate(p.location);\n",
    "    HexPiece head = table[index];\n",
    "\n",
    "    if (head != null) {{\n",
    "        HexPiece current = head;\n",
    "        do {{\n",
    "            if (current.location.equals(p.location)) {{\n",
    "                current.terrain = p.terrain;\n",
    "                version++;\n",
    "                assert wellFormed() : \"Invariant broken after add (update)\";\n",
    "                return false;\n",
    "            }}\n",
    "            current = current.nextInChain;\n",
    "        }} while (current != head);\n",
    "\n",
    "        p.nextInChain = head.nextInChain;\n",
    "        head.nextInChain = p;\n",
    "    }} else {{\n",
    "        p.nextInChain = p;\n",
    "        table[index] = p;\n",
    "    }}\n",
    "\n",
    "    connect(p);\n",
    "    size++;\n",
    "    version++;\n",
    "\n",
    "    if (size >= table.length) {{\n",
    "        rehash();\n",
    "    }}\n",
    "\n",
    "    assert wellFormed() : \"Invariant broken after add (insert)\";\n",
    "    return true;\n",
    "}}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a99540",
   "metadata": {},
   "source": [
    "# Evaluating outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6cfee",
   "metadata": {},
   "source": [
    "### Qwen2.5 coder (0.5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661a715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ollama) (2.11.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<0.29,>=0.27->ollama) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\labib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Downloading ollama-0.4.8-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.4.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\labib\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25d3440c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model \"qwen2.5-coder:0.5b\" not found, try pulling it first (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chat\n\u001b[32m      3\u001b[39m model1 = \u001b[33m'\u001b[39m\u001b[33mqwen2.5-coder:0.5b\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mremoveFromBST\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ollama\\_client.py:333\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    290\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    291\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ollama\\_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ollama\\_client.py:122\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model \"qwen2.5-coder:0.5b\" not found, try pulling it first (status code: 404)"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "from ollama import chat\n",
    "model1 = 'qwen2.5-coder:0.5b'\n",
    "response = chat(model=model1, messages=[{'role': 'user', 'content': removeFromBST}])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f7b39b",
   "metadata": {},
   "source": [
    "### Qwen 2.5 coder (32b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4194c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is the Javadoc comment for the `rehash` method based on the provided code snippet and examples:\n",
      "\n",
      "```java\n",
      "/**\n",
      " * Rehashes the table to double its capacity, redistributing existing elements.\n",
      " * This method recalculates the new capacity using the next prime number greater\n",
      " * than twice the current table length. It then re-inserts all elements into the\n",
      " * new table based on their updated hash indices.\n",
      " *\n",
      " * @throws AssertionError if the invariant of the data structure is broken during rehashing\n",
      " */\n",
      "private void rehash() {\n",
      "    int newCapacity = Primes.nextPrime(table.length * 2);\n",
      "    HexPiece[] oldTable = table;\n",
      "    table = new HexPiece[newCapacity];\n",
      "    size = 0;\n",
      "\n",
      "    for (HexPiece head : oldTable) {\n",
      "        if (head == null) continue;\n",
      "        HexPiece current = head;\n",
      "        do {\n",
      "            HexPiece next = current.nextInChain;\n",
      "            int newIndex = locate(current.location);\n",
      "\n",
      "            if (table[newIndex] == null) {\n",
      "                current.nextInChain = current;\n",
      "                table[newIndex] = current;\n",
      "            } else {\n",
      "                current.nextInChain = table[newIndex].nextInChain;\n",
      "                table[newIndex].nextInChain = current;\n",
      "            }\n",
      "            size++;\n",
      "            current = next;\n",
      "        } while (current != head);\n",
      "    }\n",
      "\n",
      "    assert wellFormed() : \"Invariant broken after rehashing\";\n",
      "}\n",
      "```\n",
      "\n",
      "This Javadoc header describes the purpose of the `rehash` method, the actions it performs, and the exception or assertion it may throw.\n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "response = chat(model=model2, messages=[{'role': 'user', 'content': longMethodWithHelper}])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91d559",
   "metadata": {},
   "source": [
    "### Wizard Coder (15B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa8f3712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/**\n",
      " * Rehashes the hash table when it gets too full. This involves creating a new, larger table and rehashing all existing elements into it.\n",
      " */\n",
      "private void rehash() {\n",
      "    int newCapacity = Primes.nextPrime(table.length * 2);\n",
      "    HexPiece[] oldTable = table;\n",
      "    table = new HexPiece[newCapacity];\n",
      "    size = 0;\n",
      "    \n",
      "    for(HexPiece head : oldTable) {\n",
      "        if (head == null) continue;\n",
      "        HexPiece current = head;\n",
      "        do {\n",
      "            HexPiece next = current.nextInChain;\n",
      "            int newIndex = locate(current.location);\n",
      "            \n",
      "            if(table[newIndex] == null) {\n",
      "                current.nextInChain = current;\n",
      "                table[newIndex] = current;\n",
      "            } else {\n",
      "                current.nextInChain = table[newIndex].nextInChain;\n",
      "                table[newIndex].nextInChain = current;\n",
      "            }\n",
      "            size++;\n",
      "            current = next;\n",
      "        } while(current != head);\n",
      "    }\n",
      "}\n",
      "\n",
      "/**\n",
      " * Adds a new HexPiece to the hash table. If a Piece with the same location already exists, it will be updated.\n",
      " *\n",
      " * @param p The piece to add or update in the hash table.\n",
      " * @return True if the element was added, false if it was updated.\n",
      " * @throws NullPointerException If the provided HexPiece, its location, or terrain are null.\n",
      " */ \n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "response = chat(model=model3, messages=[{'role': 'user', 'content': longMethodWithHelper}])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace9802",
   "metadata": {},
   "source": [
    "### Starcoder2 (15b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01e19df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "response = chat(model=model4, messages=[{'role': 'user', 'content': shortMethod}])\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
