{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 33.35087719298246,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.5383415818214417,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.0406,
      "step": 10
    },
    {
      "epoch": 1.3508771929824561,
      "grad_norm": 0.46150723099708557,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0361,
      "step": 20
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.22288283705711365,
      "learning_rate": 1.16e-05,
      "loss": 0.0189,
      "step": 30
    },
    {
      "epoch": 2.7017543859649122,
      "grad_norm": 0.09865065664052963,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0096,
      "step": 40
    },
    {
      "epoch": 3.3508771929824563,
      "grad_norm": 0.07410464435815811,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0053,
      "step": 50
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.009613812901079655,
      "learning_rate": 1.999557130777767e-05,
      "loss": 0.0027,
      "step": 60
    },
    {
      "epoch": 4.701754385964913,
      "grad_norm": 0.030477507039904594,
      "learning_rate": 1.9980267284282718e-05,
      "loss": 0.0015,
      "step": 70
    },
    {
      "epoch": 5.350877192982456,
      "grad_norm": 0.06505988538265228,
      "learning_rate": 1.9954049985041208e-05,
      "loss": 0.0018,
      "step": 80
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.04499947652220726,
      "learning_rate": 1.991694807828494e-05,
      "loss": 0.0009,
      "step": 90
    },
    {
      "epoch": 6.701754385964913,
      "grad_norm": 0.004805236589163542,
      "learning_rate": 1.9869002134404235e-05,
      "loss": 0.0004,
      "step": 100
    },
    {
      "epoch": 7.350877192982456,
      "grad_norm": 0.006477003917098045,
      "learning_rate": 1.981026458158479e-05,
      "loss": 0.0007,
      "step": 110
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.00403477530926466,
      "learning_rate": 1.9740799648478233e-05,
      "loss": 0.0004,
      "step": 120
    },
    {
      "epoch": 8.701754385964913,
      "grad_norm": 0.003907441161572933,
      "learning_rate": 1.9660683293969042e-05,
      "loss": 0.0003,
      "step": 130
    },
    {
      "epoch": 9.350877192982455,
      "grad_norm": 0.00287067168392241,
      "learning_rate": 1.9570003124114622e-05,
      "loss": 0.0003,
      "step": 140
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0020829043351113796,
      "learning_rate": 1.946885829634935e-05,
      "loss": 0.0003,
      "step": 150
    },
    {
      "epoch": 10.701754385964913,
      "grad_norm": 0.006397552788257599,
      "learning_rate": 1.9357359411057398e-05,
      "loss": 0.0003,
      "step": 160
    },
    {
      "epoch": 11.350877192982455,
      "grad_norm": 0.004969087429344654,
      "learning_rate": 1.923562839063282e-05,
      "loss": 0.0002,
      "step": 170
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.0801808089017868,
      "learning_rate": 1.9103798346159214e-05,
      "loss": 0.0002,
      "step": 180
    },
    {
      "epoch": 12.701754385964913,
      "grad_norm": 0.00864779856055975,
      "learning_rate": 1.8962013431854705e-05,
      "loss": 0.0002,
      "step": 190
    },
    {
      "epoch": 13.350877192982455,
      "grad_norm": 0.0051145111210644245,
      "learning_rate": 1.8810428687441415e-05,
      "loss": 0.0002,
      "step": 200
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.005122740752995014,
      "learning_rate": 1.8649209868611822e-05,
      "loss": 0.0002,
      "step": 210
    },
    {
      "epoch": 14.701754385964913,
      "grad_norm": 0.004541694186627865,
      "learning_rate": 1.847853326577732e-05,
      "loss": 0.0001,
      "step": 220
    },
    {
      "epoch": 15.350877192982455,
      "grad_norm": 0.0014927228912711143,
      "learning_rate": 1.8298585511297263e-05,
      "loss": 0.0002,
      "step": 230
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.0014766257954761386,
      "learning_rate": 1.81095633753992e-05,
      "loss": 0.0001,
      "step": 240
    },
    {
      "epoch": 16.70175438596491,
      "grad_norm": 0.0020165445748716593,
      "learning_rate": 1.7911673551013553e-05,
      "loss": 0.0001,
      "step": 250
    },
    {
      "epoch": 17.350877192982455,
      "grad_norm": 0.0021861849818378687,
      "learning_rate": 1.7705132427757895e-05,
      "loss": 0.0002,
      "step": 260
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.00225155521184206,
      "learning_rate": 1.7490165855318097e-05,
      "loss": 0.0001,
      "step": 270
    },
    {
      "epoch": 18.70175438596491,
      "grad_norm": 0.002854619175195694,
      "learning_rate": 1.726700889648501e-05,
      "loss": 0.0001,
      "step": 280
    },
    {
      "epoch": 19.350877192982455,
      "grad_norm": 0.0017074733041226864,
      "learning_rate": 1.703590557011677e-05,
      "loss": 0.0001,
      "step": 290
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.002019844250753522,
      "learning_rate": 1.6797108584307732e-05,
      "loss": 0.0001,
      "step": 300
    },
    {
      "epoch": 20.70175438596491,
      "grad_norm": 0.005082434043288231,
      "learning_rate": 1.6550879060055897e-05,
      "loss": 0.0001,
      "step": 310
    },
    {
      "epoch": 21.350877192982455,
      "grad_norm": 0.0013947885017842054,
      "learning_rate": 1.6297486245730925e-05,
      "loss": 0.0001,
      "step": 320
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.0006555875297635794,
      "learning_rate": 1.603720722265501e-05,
      "loss": 0.0001,
      "step": 330
    },
    {
      "epoch": 22.70175438596491,
      "grad_norm": 0.0036604804918169975,
      "learning_rate": 1.5770326602118502e-05,
      "loss": 0.0001,
      "step": 340
    },
    {
      "epoch": 23.350877192982455,
      "grad_norm": 0.002124543534591794,
      "learning_rate": 1.5497136214161662e-05,
      "loss": 0.0001,
      "step": 350
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.0007335281115956604,
      "learning_rate": 1.5217934788462774e-05,
      "loss": 0.0001,
      "step": 360
    },
    {
      "epoch": 24.70175438596491,
      "grad_norm": 0.002207426354289055,
      "learning_rate": 1.4933027627681651e-05,
      "loss": 0.0001,
      "step": 370
    },
    {
      "epoch": 25.350877192982455,
      "grad_norm": 0.0007670415798202157,
      "learning_rate": 1.4642726273615639e-05,
      "loss": 0.0001,
      "step": 380
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.0005553285591304302,
      "learning_rate": 1.4347348166533247e-05,
      "loss": 0.0001,
      "step": 390
    },
    {
      "epoch": 26.70175438596491,
      "grad_norm": 0.0010424029314890504,
      "learning_rate": 1.4047216298057872e-05,
      "loss": 0.0001,
      "step": 400
    },
    {
      "epoch": 27.350877192982455,
      "grad_norm": 0.0008322139619849622,
      "learning_rate": 1.3742658857981204e-05,
      "loss": 0.0001,
      "step": 410
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.0012691193260252476,
      "learning_rate": 1.3434008875392499e-05,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 28.70175438596491,
      "grad_norm": 0.0015142577467486262,
      "learning_rate": 1.3121603854516161e-05,
      "loss": 0.0001,
      "step": 430
    },
    {
      "epoch": 29.350877192982455,
      "grad_norm": 0.0005341923097148538,
      "learning_rate": 1.2805785405655833e-05,
      "loss": 0.0001,
      "step": 440
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.0003847376210615039,
      "learning_rate": 1.2486898871648552e-05,
      "loss": 0.0001,
      "step": 450
    },
    {
      "epoch": 30.70175438596491,
      "grad_norm": 0.0005855648778378963,
      "learning_rate": 1.21652929502374e-05,
      "loss": 0.0001,
      "step": 460
    },
    {
      "epoch": 31.350877192982455,
      "grad_norm": 0.0011565140448510647,
      "learning_rate": 1.1841319312775672e-05,
      "loss": 0.0001,
      "step": 470
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.0005862191901542246,
      "learning_rate": 1.1515332219679405e-05,
      "loss": 0.0001,
      "step": 480
    },
    {
      "epoch": 32.70175438596491,
      "grad_norm": 0.001983906840905547,
      "learning_rate": 1.1187688133048801e-05,
      "loss": 0.0001,
      "step": 490
    },
    {
      "epoch": 33.35087719298246,
      "grad_norm": 0.000582280510570854,
      "learning_rate": 1.0858745326882172e-05,
      "loss": 0.0,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 72,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5345209046676480.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
